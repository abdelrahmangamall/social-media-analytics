# Social Media Analytics Pipeline

A robust data engineering pipeline that collects, processes, and analyzes social media data from multiple platforms. The system computes engagement metrics, identifies top-performing content, and generates comprehensive analytics reports.

---

## ğŸ“‹ Features
- **Multi-Platform Data Collection:** Supports YouTube, Facebook, and Twitter APIs  
- **Data Normalization:** Unified schema across all social media platforms  
- **Advanced Analytics:** Daily engagement metrics, top posts identification, moving averages  
- **Error Handling:** Robust error handling and fallback mechanisms  
- **Automation:** Ready for daily execution and Airflow scheduling  
- **Multiple Output Formats:** CSV and Parquet file support  


---
## ğŸ—ï¸ Project Structure
```bash

social-media-analytics/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ api_config.py
â”‚   â””â”€â”€ credentials.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ base_client.py
â”‚   â”‚   â”œâ”€â”€ youtube_client.py
â”‚   â”‚   â”œâ”€â”€ facebook_client.py
â”‚   â”‚   â””â”€â”€ twitter_client.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ data_processor.py
â”‚   â”‚   â”œâ”€â”€ analyzer.py
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â””â”€â”€ config_checker.py
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ results.py
â”‚       â””â”€â”€ airflow_dag.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_pipeline.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ analytics/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

## ğŸš€ Quick Start


### Run the pipeline
```bash
# Method 1: Using the script
python scripts/run_pipeline.py

# Method 2: Directly from main
python -m src.pipeline.main

# Method 3: View results
python -m src.pipeline.results
```
---
### Prerequisites
- Python 3.8+  
- YouTube API key  
- Twitter API credentials *(optional)*  
- Facebook access token *(optional)*  

### Installation
Clone the repository:
```bash
git clone <repository-url>
cd social-media-analytics

Install dependencies:

pip install -r requirements.txt


Configure API credentials by creating a .env file:

YOUTUBE_API_KEY=your_youtube_api_key_here
TWITTER_API_KEY=your_twitter_api_key_here
TWITTER_API_SECRET=your_twitter_api_secret_here
TWITTER_ACCESS_TOKEN=your_twitter_access_token_here
TWITTER_ACCESS_SECRET=your_twitter_access_secret_here
FACEBOOK_ACCESS_TOKEN=your_facebook_access_token_here

Usage

Run the pipeline:

python scripts/run_pipeline.py


Or directly:

python -m src.pipeline.main


View results:

python -m src.pipeline.results

ğŸ“Š Output Files

data/raw/real_data_*.parquet â†’ Raw collected data

data/processed/processed_real_data_*.parquet â†’ Normalized data

data/analytics/real_daily_metrics_*.csv â†’ Daily engagement metrics

data/analytics/real_top_posts_overall_*.csv â†’ Top 5 posts overall

data/analytics/real_top_posts_platform_*.csv â†’ Top 3 posts per platform

ğŸ”§ API Support

âœ… YouTube API â€“ Fully functional, requires API key

âœ… Facebook API â€“ Mock data (real API requires access token)

âš ï¸ Twitter API â€“ Limited (requires paid access), uses fallback

ğŸ“ˆ Analytics Features

Daily Metrics: Engagement score sum/mean/count, likes/comments/shares totals, 7-day moving average

Top Posts: Top 5 overall + top 3 per platform by engagement

Data Processing: Schema normalization, missing value handling, timestamp standardization, engagement score calculation

ğŸ› ï¸ Configuration

Modify config/api_config.py for:

Search queries and parameters

Rate limits and request limits

Platform-specific settings

ğŸ”„ Automation

Airflow Integration: Use the provided DAG for scheduled execution

Manual Scheduling: Add to crontab for daily execution:

0 0 * * * cd /path/to/social-media-analytics && python scripts/run_pipeline.py

ğŸ› Troubleshooting

Common Issues:

YouTube API errors â†’ Verify API key and enable YouTube Data API v3

SSL errors â†’ Update certificates with pip install --upgrade certifi

Import errors â†’ Set Python path:

export PYTHONPATH=/path/to/project


Data not collected â†’ Check API quotas and network connectivity

Debug Mode:

python scripts/run_pipeline.py --debug

ğŸ“ License

Educational use only. Ensure compliance with API terms of service.

ğŸ¤ Contributing

Fork repository

Create feature branch

Make changes and test

Submit pull request
